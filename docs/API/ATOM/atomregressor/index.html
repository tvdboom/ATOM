<!DOCTYPE html>
<html lang="en">
    <head>
        <meta charset="utf-8">
        <meta http-equiv="X-UA-Compatible" content="IE=edge">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        
        <meta name="author" content="tvdboom">
        <link rel="canonical" href="http://tvdboom.github.io/ATOM/API/ATOM/atomregressor/">
        <link rel="shortcut icon" href="../../../img/favicon.ico">
        <title>ATOMRegressor - ATOM</title>
        <link href="../../../css/bootstrap.min.css" rel="stylesheet">
        <link href="../../../css/font-awesome.min.css" rel="stylesheet">
        <link href="../../../css/base.css" rel="stylesheet">
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/color-brewer.min.css">

        <script src="../../../js/jquery-1.10.2.min.js" defer></script>
        <script src="../../../js/bootstrap.min.js" defer></script>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/highlight.min.js"></script>
        <script>hljs.initHighlightingOnLoad();</script> 
    </head>

    <body>
        <div class="navbar fixed-top navbar-expand-lg navbar-dark bg-primary">
            <div class="container">
                <a class="navbar-brand" href="../../..">ATOM</a>
                <!-- Expander button -->
                <button type="button" class="navbar-toggler" data-toggle="collapse" data-target="#navbar-collapse">
                    <span class="navbar-toggler-icon"></span>
                </button>

                <!-- Expanded navigation -->
                <div id="navbar-collapse" class="navbar-collapse collapse">
                        <!-- Main navigation -->
                        <ul class="nav navbar-nav">
                            <li class="navitem">
                                <a href="../../../getting_started/" class="nav-link">Getting started</a>
                            </li>
                            <li class="navitem">
                                <a href="../../../user_guide/" class="nav-link">User guide</a>
                            </li>
                            <li class="dropdown active">
                                <a href="#" class="nav-link dropdown-toggle" data-toggle="dropdown">API <b class="caret"></b></a>
                                <ul class="dropdown-menu">
                                    
  <li class="dropdown-submenu">
    <a href="#" class="dropdown-item">ATOM</a>
    <ul class="dropdown-menu">
            
<li>
    <a href="../atomclassifier/" class="dropdown-item">ATOMClassifier</a>
</li>
            
<li>
    <a href="./" class="dropdown-item active">ATOMRegressor</a>
</li>
            
<li>
    <a href="../atomloader/" class="dropdown-item">ATOMLoader</a>
</li>
            
<li>
    <a href="../atommodel/" class="dropdown-item">ATOMModel</a>
</li>
    </ul>
  </li>
                                    
  <li class="dropdown-submenu">
    <a href="#" class="dropdown-item">Data cleaning</a>
    <ul class="dropdown-menu">
            
<li>
    <a href="../../data_cleaning/scaler/" class="dropdown-item">Scaler</a>
</li>
            
<li>
    <a href="../../data_cleaning/cleaner/" class="dropdown-item">Cleaner</a>
</li>
            
<li>
    <a href="../../data_cleaning/imputer/" class="dropdown-item">Imputer</a>
</li>
            
<li>
    <a href="../../data_cleaning/encoder/" class="dropdown-item">Encoder</a>
</li>
            
<li>
    <a href="../../data_cleaning/pruner/" class="dropdown-item">Pruner</a>
</li>
            
<li>
    <a href="../../data_cleaning/balancer/" class="dropdown-item">Balancer</a>
</li>
    </ul>
  </li>
                                    
  <li class="dropdown-submenu">
    <a href="#" class="dropdown-item">Feature engineering</a>
    <ul class="dropdown-menu">
            
<li>
    <a href="../../feature_engineering/feature_generator/" class="dropdown-item">FeatureGenerator</a>
</li>
            
<li>
    <a href="../../feature_engineering/feature_selector/" class="dropdown-item">FeatureSelector</a>
</li>
    </ul>
  </li>
                                    
  <li class="dropdown-submenu">
    <a href="#" class="dropdown-item">Training</a>
    <ul class="dropdown-menu">
            
  <li class="dropdown-submenu">
    <a href="#" class="dropdown-item">Direct</a>
    <ul class="dropdown-menu">
            
<li>
    <a href="../../training/directclassifier/" class="dropdown-item">DirectClassifier</a>
</li>
            
<li>
    <a href="../../training/directregressor/" class="dropdown-item">DirectRegressor</a>
</li>
    </ul>
  </li>
            
  <li class="dropdown-submenu">
    <a href="#" class="dropdown-item">SuccessiveHalving</a>
    <ul class="dropdown-menu">
            
<li>
    <a href="../../training/successivehalvingclassifier/" class="dropdown-item">SuccessiveHalvingClassifier</a>
</li>
            
<li>
    <a href="../../training/successivehalvingregressor/" class="dropdown-item">SuccessiveHalvingRegressor</a>
</li>
    </ul>
  </li>
            
  <li class="dropdown-submenu">
    <a href="#" class="dropdown-item">TrainSizing</a>
    <ul class="dropdown-menu">
            
<li>
    <a href="../../training/trainsizingclassifier/" class="dropdown-item">TrainSizingClassifier</a>
</li>
            
<li>
    <a href="../../training/trainsizingregressor/" class="dropdown-item">TrainSizingRegressor</a>
</li>
    </ul>
  </li>
    </ul>
  </li>
                                    
  <li class="dropdown-submenu">
    <a href="#" class="dropdown-item">Models</a>
    <ul class="dropdown-menu">
            
<li>
    <a href="../../models/gp/" class="dropdown-item">Gaussian Process</a>
</li>
            
<li>
    <a href="../../models/gnb/" class="dropdown-item">Gaussian Naive Bayes</a>
</li>
            
<li>
    <a href="../../models/mnb/" class="dropdown-item">Multinomial Naive Bayes</a>
</li>
            
<li>
    <a href="../../models/bnb/" class="dropdown-item">Bernoulli Naive Bayes</a>
</li>
            
<li>
    <a href="../../models/catnb/" class="dropdown-item">Categorical Naive Bayes</a>
</li>
            
<li>
    <a href="../../models/cnb/" class="dropdown-item">Complement Naive Bayes</a>
</li>
            
<li>
    <a href="../../models/ols/" class="dropdown-item">Ordinary Least Squares</a>
</li>
            
<li>
    <a href="../../models/ridge/" class="dropdown-item">Ridge</a>
</li>
            
<li>
    <a href="../../models/lasso/" class="dropdown-item">Lasso</a>
</li>
            
<li>
    <a href="../../models/en/" class="dropdown-item">Elastic Net</a>
</li>
            
<li>
    <a href="../../models/br/" class="dropdown-item">Bayesian Ridge</a>
</li>
            
<li>
    <a href="../../models/ard/" class="dropdown-item">Automated Relevance Determination</a>
</li>
            
<li>
    <a href="../../models/lr/" class="dropdown-item">Logistic Regression</a>
</li>
            
<li>
    <a href="../../models/lda/" class="dropdown-item">Linear Discriminant Analysis</a>
</li>
            
<li>
    <a href="../../models/qda/" class="dropdown-item">Quadratic Discriminant Analysis</a>
</li>
            
<li>
    <a href="../../models/knn/" class="dropdown-item">K-Nearest Neighbors</a>
</li>
            
<li>
    <a href="../../models/rnn/" class="dropdown-item">Radius Nearest Neighbors</a>
</li>
            
<li>
    <a href="../../models/tree/" class="dropdown-item">Decision Tree</a>
</li>
            
<li>
    <a href="../../models/bag/" class="dropdown-item">Bagging</a>
</li>
            
<li>
    <a href="../../models/et/" class="dropdown-item">Extra-Trees</a>
</li>
            
<li>
    <a href="../../models/rf/" class="dropdown-item">Random Forest</a>
</li>
            
<li>
    <a href="../../models/adab/" class="dropdown-item">AdaBoost</a>
</li>
            
<li>
    <a href="../../models/gbm/" class="dropdown-item">Gradient Boosting Machine</a>
</li>
            
<li>
    <a href="../../models/xgb/" class="dropdown-item">XGBoost</a>
</li>
            
<li>
    <a href="../../models/lgb/" class="dropdown-item">LightGBM</a>
</li>
            
<li>
    <a href="../../models/catb/" class="dropdown-item">CatBoost</a>
</li>
            
<li>
    <a href="../../models/lsvm/" class="dropdown-item">Linear-SVM</a>
</li>
            
<li>
    <a href="../../models/ksvm/" class="dropdown-item">Kernel-SVM</a>
</li>
            
<li>
    <a href="../../models/pa/" class="dropdown-item">Passive Aggressive</a>
</li>
            
<li>
    <a href="../../models/sgd/" class="dropdown-item">Stochastic Gradient Descent</a>
</li>
            
<li>
    <a href="../../models/mlp/" class="dropdown-item">Multi-layer Perceptron</a>
</li>
    </ul>
  </li>
                                    
  <li class="dropdown-submenu">
    <a href="#" class="dropdown-item">Predicting</a>
    <ul class="dropdown-menu">
            
<li>
    <a href="../../predicting/transform/" class="dropdown-item">transform</a>
</li>
            
<li>
    <a href="../../predicting/predict/" class="dropdown-item">predict</a>
</li>
            
<li>
    <a href="../../predicting/predict_proba/" class="dropdown-item">predict_proba</a>
</li>
            
<li>
    <a href="../../predicting/predict_log_proba/" class="dropdown-item">predict_log_proba</a>
</li>
            
<li>
    <a href="../../predicting/decision_function/" class="dropdown-item">decision_function</a>
</li>
            
<li>
    <a href="../../predicting/score/" class="dropdown-item">score</a>
</li>
    </ul>
  </li>
                                    
  <li class="dropdown-submenu">
    <a href="#" class="dropdown-item">Plots</a>
    <ul class="dropdown-menu">
            
<li>
    <a href="../../plots/plot_correlation/" class="dropdown-item">plot_correlation</a>
</li>
            
<li>
    <a href="../../plots/plot_pipeline/" class="dropdown-item">plot_pipeline</a>
</li>
            
<li>
    <a href="../../plots/plot_pca/" class="dropdown-item">plot_pca</a>
</li>
            
<li>
    <a href="../../plots/plot_components/" class="dropdown-item">plot_components</a>
</li>
            
<li>
    <a href="../../plots/plot_rfecv/" class="dropdown-item">plot_rfecv</a>
</li>
            
<li>
    <a href="../../plots/plot_successive_halving/" class="dropdown-item">plot_successive_halving</a>
</li>
            
<li>
    <a href="../../plots/plot_learning_curve/" class="dropdown-item">plot_learning_curve</a>
</li>
            
<li>
    <a href="../../plots/plot_results/" class="dropdown-item">plot_results</a>
</li>
            
<li>
    <a href="../../plots/plot_bo/" class="dropdown-item">plot_bo</a>
</li>
            
<li>
    <a href="../../plots/plot_evals/" class="dropdown-item">plot_evals</a>
</li>
            
<li>
    <a href="../../plots/plot_roc/" class="dropdown-item">plot_roc</a>
</li>
            
<li>
    <a href="../../plots/plot_prc/" class="dropdown-item">plot_prc</a>
</li>
            
<li>
    <a href="../../plots/plot_permutation_importance/" class="dropdown-item">plot_permutation_importance</a>
</li>
            
<li>
    <a href="../../plots/plot_feature_importance/" class="dropdown-item">plot_feature_importance</a>
</li>
            
<li>
    <a href="../../plots/plot_partial_dependence/" class="dropdown-item">plot_partial_dependence</a>
</li>
            
<li>
    <a href="../../plots/plot_errors/" class="dropdown-item">plot_errors</a>
</li>
            
<li>
    <a href="../../plots/plot_residuals/" class="dropdown-item">plot_residuals</a>
</li>
            
<li>
    <a href="../../plots/plot_confusion_matrix/" class="dropdown-item">plot_confusion_matrix</a>
</li>
            
<li>
    <a href="../../plots/plot_threshold/" class="dropdown-item">plot_threshold</a>
</li>
            
<li>
    <a href="../../plots/plot_probabilities/" class="dropdown-item">plot_probabilities</a>
</li>
            
<li>
    <a href="../../plots/plot_calibration/" class="dropdown-item">plot_calibration</a>
</li>
            
<li>
    <a href="../../plots/plot_gains/" class="dropdown-item">plot_gains</a>
</li>
            
<li>
    <a href="../../plots/plot_lift/" class="dropdown-item">plot_lift</a>
</li>
            
<li>
    <a href="../../plots/bar_plot/" class="dropdown-item">bar_plot</a>
</li>
            
<li>
    <a href="../../plots/beeswarm_plot/" class="dropdown-item">beeswarm_plot</a>
</li>
            
<li>
    <a href="../../plots/decision_plot/" class="dropdown-item">decision_plot</a>
</li>
            
<li>
    <a href="../../plots/force_plot/" class="dropdown-item">force_plot</a>
</li>
            
<li>
    <a href="../../plots/heatmap_plot/" class="dropdown-item">heatmap_plot</a>
</li>
            
<li>
    <a href="../../plots/scatter_plot/" class="dropdown-item">scatter_plot</a>
</li>
            
<li>
    <a href="../../plots/waterfall_plot/" class="dropdown-item">waterfall_plot</a>
</li>
    </ul>
  </li>
                                </ul>
                            </li>
                            <li class="dropdown">
                                <a href="#" class="nav-link dropdown-toggle" data-toggle="dropdown">Examples <b class="caret"></b></a>
                                <ul class="dropdown-menu">
                                    
<li>
    <a href="../../../examples/automl.html" target="_blank" class="dropdown-item">AutoML</a>
</li>
                                    
<li>
    <a href="../../../examples/binary_classification.html" target="_blank" class="dropdown-item">Binary classification</a>
</li>
                                    
<li>
    <a href="../../../examples/calibration.html" target="_blank" class="dropdown-item">Calibration</a>
</li>
                                    
<li>
    <a href="../../../examples/deep_learning.html" target="_blank" class="dropdown-item">Deep learning</a>
</li>
                                    
<li>
    <a href="../../../examples/early_stopping.html" target="_blank" class="dropdown-item">Early stopping</a>
</li>
                                    
<li>
    <a href="../../../examples/ensembles.html" target="_blank" class="dropdown-item">Ensembles</a>
</li>
                                    
<li>
    <a href="../../../examples/feature_engineering.html" target="_blank" class="dropdown-item">Feature engineering</a>
</li>
                                    
<li>
    <a href="../../../examples/imbalanced_datasets.html" target="_blank" class="dropdown-item">Imbalanced datasets</a>
</li>
                                    
<li>
    <a href="../../../examples/multiclass_classification.html" target="_blank" class="dropdown-item">Multiclass classification</a>
</li>
                                    
<li>
    <a href="../../../examples/multi_metric.html" target="_blank" class="dropdown-item">Multi-metric runs</a>
</li>
                                    
<li>
    <a href="../../../examples/regression.html" target="_blank" class="dropdown-item">Regression</a>
</li>
                                    
<li>
    <a href="../../../examples/successive_halving.html" target="_blank" class="dropdown-item">Successive halving</a>
</li>
                                    
<li>
    <a href="../../../examples/train_sizing.html" target="_blank" class="dropdown-item">Train sizing</a>
</li>
                                    
<li>
    <a href="../../../examples/utilities.html" target="_blank" class="dropdown-item">Utilities</a>
</li>
                                </ul>
                            </li>
                            <li class="navitem">
                                <a href="../../../dependencies/" class="nav-link">Dependencies</a>
                            </li>
                            <li class="navitem">
                                <a href="../../../license/" class="nav-link">License</a>
                            </li>
                        </ul>

                    <ul class="nav navbar-nav ml-auto">
                        <li class="nav-item">
                            <a href="#" class="nav-link" data-toggle="modal" data-target="#mkdocs_search_modal">
                                <i class="fa fa-search"></i> Search
                            </a>
                        </li>
                            <li class="nav-item">
                                <a rel="prev" href="../atomclassifier/" class="nav-link">
                                    <i class="fa fa-arrow-left"></i> Previous
                                </a>
                            </li>
                            <li class="nav-item">
                                <a rel="next" href="../atomloader/" class="nav-link">
                                    Next <i class="fa fa-arrow-right"></i>
                                </a>
                            </li>
                            <li class="nav-item">
                                <a href="https://github.com/tvdboom/ATOM" class="nav-link"><i class="fa fa-github"></i> GitHub</a>
                            </li>
                    </ul>
                </div>
            </div>
        </div>

        <div class="container">
            <div class="row">
                    <div class="col-md-3"><div class="navbar-light navbar-expand-md bs-sidebar hidden-print affix" role="complementary">
    <div class="navbar-header">
        <button type="button" class="navbar-toggler collapsed" data-toggle="collapse" data-target="#toc-collapse" title="Table of Contents">
            <span class="fa fa-angle-down"></span>
        </button>
    </div>

    
    <div id="toc-collapse" class="navbar-collapse collapse card bg-secondary">
        <ul class="nav flex-column">
            
            <li class="nav-item" data-level="1"><a href="#atomregressor" class="nav-link">ATOMRegressor</a>
              <ul class="nav flex-column">
            <li class="nav-item" data-level="2"><a href="#attributes" class="nav-link">Attributes</a>
              <ul class="nav flex-column">
              </ul>
            </li>
            <li class="nav-item" data-level="2"><a href="#utility-methods" class="nav-link">Utility methods</a>
              <ul class="nav flex-column">
              </ul>
            </li>
            <li class="nav-item" data-level="2"><a href="#data-cleaning" class="nav-link">Data cleaning</a>
              <ul class="nav flex-column">
              </ul>
            </li>
            <li class="nav-item" data-level="2"><a href="#feature-engineering" class="nav-link">Feature engineering</a>
              <ul class="nav flex-column">
              </ul>
            </li>
            <li class="nav-item" data-level="2"><a href="#training" class="nav-link">Training</a>
              <ul class="nav flex-column">
              </ul>
            </li>
            <li class="nav-item" data-level="2"><a href="#example" class="nav-link">Example</a>
              <ul class="nav flex-column">
              </ul>
            </li>
              </ul>
            </li>
        </ul>
    </div>
</div></div>
                    <div class="col-md-9" role="main">

<h1 id="atomregressor">ATOMRegressor</h1>
<hr />
<pre><em>class</em> atom.api.<strong style="color:#008AB8">ATOMRegressor</strong>(*arrays, n_rows=1, test_size=0.2, logger=None,
                             n_jobs=1, warnings=True, verbose=0, random_state=None)
<div align="right"><a href="https://github.com/tvdboom/ATOM/blob/master/atom/api.py#L307">[source]</a></div></pre>
<p>ATOMRegressor is ATOM's wrapper for regression tasks. Use this class to easily apply
all data transformations and model management provided by the package on a given
dataset. Note that contrary to scikit-learn's API, an ATOMRegressor instance already
contains the dataset on which we want to perform the analysis. Calling a method will
automatically apply it on the dataset it contains.</p>
<p>You can <a href="../../../user_guide/#predicting">predict</a>, <a href="../../../user_guide/#plots">plot</a>
 and call any <a href="../../../user_guide/#models">model</a> from atom. Read more in the
 <a href="../../../user_guide/#first-steps">user guide</a>.</p>
<table>
<tr>
<td width="20%" style="vertical-align:top; background:#F5F5F5;"><strong>Parameters:</strong></td>
<td width="80%" style="background:white;">
<strong>*arrays: sequence of indexables</strong>
<blockquote>
Dataset containing features and target. Allowed formats are:
<ul>
<li>X, y</li>
<li>train, test</li>
<li>X_train, X_test, y_train, y_test</li>
<li>(X_train, y_train), (X_test, y_test)</li>
</ul>
X, train, test: dict, list, tuple, np.ndarray or pd.DataFrame<br>
&nbsp;&nbsp;&nbsp;&nbsp;
Feature set with shape=(n_features, n_samples). If no y is provided,
 the last column is used as target.<br><br>
y: int, str or sequence<br>
<ul>
<li>If int: Position of the target column in X.</li>
<li>If str: Name of the target column in X.</li>
<li>Else: Target column with shape=(n_samples,).</li>
</ul>
</blockquote>
<strong>n_rows: int or float, optional (default=1)</strong>
<blockquote>
<ul>
<li>If <=1: Fraction of the dataset to use.</li>
<li>If >1: Number of rows to use (only if input is X, y).</li>
</ul>
</blockquote>
<strong>test_size: int, float, optional (default=0.2)</strong>
<blockquote>
<ul>
<li>If <=1: Fraction of the dataset to include in the test set.</li>
<li>If >1: Number of rows to include in the test set.</li>
</ul>
This parameter is ignored if the train and test set are provided.
</blockquote>
<strong>n_jobs: int, optional (default=1)</strong>
<blockquote>
Number of cores to use for parallel processing.
<ul>
<li>If >0: Number of cores to use.</li>
<li>If -1: Use all available cores.</li>
<li>If <-1: Use available_cores - 1 + n_jobs.</li>
</ul>
Beware that using multiple processes on the same machine may cause
 memory issues for large datasets.
</blockquote>
<strong>verbose: int, optional (default=0)</strong>
<blockquote>
Verbosity level of the class. Possible values are:
<ul>
<li>0 to not print anything.</li>
<li>1 to print basic information.</li>
<li>2 to print detailed information.</li>
</ul>
</blockquote>
<strong>warnings: bool or str, optional (default=True)</strong>
<blockquote>
<ul>
<li>If True: Default warning action (equal to "default").</li>
<li>If False: Suppress all warnings (equal to "ignore").</li>
<li>If str: One of the actions in python's warnings environment.</li>
</ul>
Note that changing this parameter will affect the <code>PYTHONWARNINGS</code> environment.
<br>
Note that ATOM can't manage warnings that go directly from C++ code to the
 stdout/stderr.
</blockquote>
<strong>logger: str, class or None, optional (default=None)</strong>
<blockquote>
<ul>
<li>If None: Doesn't save a logging file.</li>
<li>If str: Name of the logging file. Use "auto" for default name.</li>
<li>If class: python <code>Logger</code> object.</li>
</ul>
The default name consists of the class' name followed by the
 timestamp of the logger's creation.
</blockquote>
<strong>random_state: int or None, optional (default=None)</strong>
<blockquote>
Seed used by the random number generator. If None, the random number
 generator is the <code>RandomState</code> instance used by <code>numpy.random</code>.
</blockquote>
</td>
</tr>
</table>
<p><br></p>
<h2 id="attributes">Attributes</h2>
<hr />
<h3 id="data-attributes">Data attributes</h3>
<p>The dataset can be accessed at any time through multiple attributes, e.g. calling
<code>trainer.train</code> will return the training set. The data can also be changed through
these attributes, e.g. <code>trainer.test = atom.test.drop(0)</code> will drop the first row
from the test set. Updating one of the data attributes will automatically update the
rest as well. Changing the branch will also change the response from these attributes
accordingly.</p>
<table>
<tr>
<td width="15%" style="vertical-align:top; background:#F5F5F5;"><strong>Attributes:</strong></td>
<td width="75%" style="background:white;">
<strong>pipeline: pd.Series</strong>
<blockquote>
Series containing all data cleaning and feature engineering classes fitted on the
 data in the current branch. Use this attribute only to access the individual instances.
 To visualize the pipeline, use atom's __repr__ or the <a href="../../plots/plot_pipeline">plot_pipeline</a> method.
</blockquote>
<strong>feature_importance: list or None</strong>
<blockquote>
Features ordered by most to least important. Is only created after running the
 <a href="#feature-selection">feature_selection</a>, <a href="../../plots/plot_permutation_importance">plot_permutation_importance</a>
 or <a href="../../plots/plot_feature_importance">plot_feature_importance</a> methods.
</blockquote>
<strong>dataset: pd.DataFrame</strong>
<blockquote>
Complete dataset in the pipeline.
</blockquote>
<strong>train: pd.DataFrame</strong>
<blockquote>
Training set.
</blockquote>
<strong>test: pd.DataFrame</strong>
<blockquote>
Test set.
</blockquote>
<strong>X: pd.DataFrame</strong>
<blockquote>
Feature set.
</blockquote>
<strong>y: pd.Series</strong>
<blockquote>
Target column.
</blockquote>
<strong>X_train: pd.DataFrame</strong>
<blockquote>
Training features.
</blockquote>
<strong>y_train: pd.Series</strong>
<blockquote>
Training target.
</blockquote>
<strong>X_test: pd.DataFrame</strong>
<blockquote>
Test features.
</blockquote>
<strong>y_test: pd.Series</strong>
<blockquote>
Test target.
</blockquote>
<strong>shape: tuple</strong>
<blockquote>
Dataset's shape: (n_rows x n_columns) or
(n_rows, (shape_sample), n_cols) for deep learning datasets.
</blockquote>
<strong>columns: list</strong>
<blockquote>
Names of the columns in the dataset.
</blockquote>
<strong>n_columns: int</strong>
<blockquote>
Number of columns in the dataset.
</blockquote>
<strong>features: list</strong>
<blockquote>
Names of the features in the dataset.
</blockquote>
<strong>n_features: int</strong>
<blockquote>
Number of features in the dataset.
</blockquote>
<strong>target: str</strong>
<blockquote>
Name of the target column.
</blockquote>
<strong>scaled: bool</strong>
<blockquote>
Whether the feature set is scaled. It is considered scaled when
it has mean=0 and std=1, or when atom has a scaler in the pipeline.
</blockquote>
<strong>nans: pd.Series</strong>
<blockquote>
Columns with the number of missing values in them.
</blockquote>
<strong>n_nans: int</strong>
<blockquote>
Number of samples containing missing values.
</blockquote>
<strong>numerical: list</strong>
<blockquote>
Names of the numerical columns in the dataset.
</blockquote>
<strong>n_numerical: int</strong>
<blockquote>
Number of numerical columns in the dataset.
</blockquote>
<strong>categorical: list</strong>
<blockquote>
Names of the categorical columns in the dataset.
</blockquote>
<strong>n_categorical: int</strong>
<blockquote>
Number of categorical columns in the dataset.
</blockquote>
<strong>outliers: pd.Series</strong>
<blockquote>
Columns in training set with amount of outlier values.
</blockquote>
<strong>n_outliers: int</strong>
<blockquote>
Returns the total number of rows containing outliers.
</blockquote>
</td></tr>
</table>
<p><br></p>
<h3 id="utility-attributes">Utility attributes</h3>
<table>
<tr>
<td width="15%" style="vertical-align:top; background:#F5F5F5;"><strong>Attributes:</strong></td>
<td width="75%" style="background:white;">
<strong>missing: list</strong>
<blockquote>
List of values that are considered "missing" (used by the <a href="#clean">clean</a>
and <a href="#impute">impute</a> methods). Default values are: "", "?", "None", "NA",
"nan", "NaN" and "inf". Note that <code>None</code>, <code>NaN</code>, <code>+inf</code>
and <code>-inf</code> are always considered missing since they are incompatible with
sklearn estimators.
</blockquote>
<strong>models: list</strong>
<blockquote>
List of models in the pipeline.
</blockquote>
<strong>metric: str or list</strong>
<blockquote>
Metric(s) used to fit the models.
</blockquote>
<strong>errors: dict</strong>
<blockquote>
Dictionary of the encountered exceptions (if any).
</blockquote>
<strong>winner: <a href="../../../user_guide/#models">model</a></strong>
<blockquote>
Model subclass that performed best on the test set.
</blockquote>
<strong>results: pd.DataFrame</strong>
<blockquote>
Dataframe of the training results. Columns can include:
<ul>
<li><b>metric_bo:</b> Best score achieved during the BO.</li>
<li><b>time_bo:</b> Time spent on the BO.</li>
<li><b>metric_train:</b> Metric score on the training set.</li>
<li><b>metric_test:</b> Metric score on the test set.</li>
<li><b>time_fit:</b> Time spent fitting and evaluating.</li>
<li><b>mean_bagging:</b> Mean score of the bagging's results.</li>
<li><b>std_bagging:</b> Standard deviation score of the bagging's results.</li>
<li><b>time_bagging:</b> Time spent on the bagging algorithm.</li>
<li><b>time:</b> Total time spent on the whole run.</li>
</ul>
</blockquote>
</td>
</tr>
</table>
<p><br></p>
<h3 id="plot-attributes">Plot attributes</h3>
<table>
<tr>
<td width="15%" style="vertical-align:top; background:#F5F5F5;"><strong>Attributes:</strong></td>
<td width="75%" style="background:white;">
<strong>style: str</strong>
<blockquote>
Plotting style. See seaborn's <a href="https://seaborn.pydata.org/tutorial/aesthetics.html#seaborn-figure-styles">documentation</a>.
</blockquote>
<strong>palette: str</strong>
<blockquote>
Color palette. See seaborn's <a href="https://seaborn.pydata.org/tutorial/color_palettes.html">documentation</a>.
</blockquote>
<strong>title_fontsize: int</strong>
<blockquote>
Fontsize for the plot's title.
</blockquote>
<strong>label_fontsize: int</strong>
<blockquote>
Fontsize for labels and legends.
</blockquote>
<strong>tick_fontsize: int</strong>
<blockquote>
Fontsize for the ticks along the plot's axes.
</blockquote>
</td></tr>
</table>
<p><br><br></p>
<h2 id="utility-methods">Utility methods</h2>
<hr />
<p>The ATOMRegressor class contains a variety of methods to help you handle the data and
inspect the pipeline.</p>
<table>
<tr>
<td><a href="#add">add</a></td>
<td>Add a transformer to the current branch.</td>
</tr>

<tr>
<td><a href="#automl">automl</a></td>
<td>Use AutoML to search for an optimized pipeline.</td>
</tr>

<tr>
<td width="15%"><a href="#canvas">canvas</a></td>
<td>Create a figure with multiple plots.</td>
</tr>

<tr>
<td width="15%"><a href="#delete">delete</a></td>
<td>Remove a model from the pipeline.</td>
</tr>

<tr>
<td><a href="#export-pipeline">export_pipeline</a></td>
<td>Export atom's pipeline to a sklearn's Pipeline object.</td>
</tr>

<tr>
<td width="15%"><a href="#log">log</a></td>
<td>Save information to the logger and print to stdout.</td>
</tr>

<tr>
<td><a href="#report">report</a></td>
<td>Get an extensive profile analysis of the data.</td>
</tr>

<tr>
<td><a href="#reset-aesthetics">reset_aesthetics</a></td>
<td>Reset the plot aesthetics to their default values.</td>
</tr>

<tr>
<td><a href="#reset-predictions">reset_predictions</a></td>
<td>Clear the prediction attributes from all models.</td>
</tr>

<tr>
<td><a href="#save">save</a></td>
<td>Save the instance to a pickle file.</td>
</tr>

<tr>
<td width="15%"><a href="#save-data">save_data</a></td>
<td>Save data to a csv file.</td>
</tr>

<tr>
<td><a href="#scoring">scoring</a></td>
<td>Returns the scores of the models for a specific metric.</td>
</tr>

<tr>
<td><a href="#stacking">stacking</a></td>
<td>Add a Stacking instance to the models in the pipeline.</td>
</tr>

<tr>
<td width="15%"><a href="#stats">stats</a></td>
<td>Print out a list of basic statistics on the dataset.</td>
</tr>

<tr>
<td><a href="#voting">voting</a></td>
<td>Add a Voting instance to the models in the pipeline.</td>
</tr>
</table>
<p><br></p>
<p><a name="add"></a></p>
<pre><em>method</em> <strong style="color:#008AB8">add</strong>(transformer, name=None, columns=None, train_only=False)
<div align="right"><a href="https://github.com/tvdboom/ATOM/blob/master/atom/atom.py#L365">[source]</a></div></pre>
<p>Add a transformer to the current branch. If the transformer is not fitted,
it is fitted on the complete training set. Afterwards, the data set is
transformed and the transformer is added to atom's pipeline. If the transformer
is a sklearn Pipeline, every step will be transformed independently on the
complete data set.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>If the transformer has a <code>n_jobs</code> and/or <code>random_state</code> parameter and it
is left to its default value, it adopts atom's value.</p>
</div>
<table>
<tr>
<td width="15%" style="vertical-align:top; background:#F5F5F5;"><strong>Parameters:</strong></td>
<td width="75%" style="background:white;">
<strong>transformer: class</strong>
<blockquote>
Transformer to add to the pipeline. Should implement a <code>transform</code> method.
</blockquote>
<strong>name: str or None, optional (default=None)</strong>
<blockquote>
Name of the transformation step. If None, it defaults to
the __name__ of the transformer's class (lower case).
</blockquote>
<strong>columns: slice, list or None, optional (default=None)</strong>
<blockquote>
Names or indices of the columns in the dataset to transform.
If None, all columns are used.
</blockquote>
<strong>train_only: bool, optional (default=False)</strong>
<blockquote>
Whether to apply the transformer only on the train set or
on the complete dataset.
</blockquote>
</tr>
</table>
<p><br /></p>
<p><a name="automl"></a></p>
<pre><em>method</em> <strong style="color:#008AB8">automl</strong>(**kwargs)
<div align="right"><a href="https://github.com/tvdboom/ATOM/blob/master/atom/atom.py#L721">[source]</a></div></pre>
<p>Uses the <a href="http://epistasislab.github.io/tpot/">TPOT</a> package to perform
an automated search of transformers and a final estimator that maximizes
a metric on the dataset. The resulting transformations and estimator are
merged with atom's pipeline. The tpot instance can be accessed through the
<code>tpot</code> attribute. Read more in the <a href="../../../user_guide/#automl">user guide</a>.</p>
<table>
<tr>
<td width="15%" style="vertical-align:top; background:#F5F5F5;"><strong>Parameters:</strong></td>
<td width="75%" style="background:white;">
<strong>**kwargs</strong>
<blockquote>
Keyword arguments for tpot's regressor.
</blockquote>
</tr>
</table>
<p><br /></p>
<p><a name="canvas"></a></p>
<pre><em>method</em> <strong style="color:#008AB8">canvas</strong>(nrows=1, ncols=2, title=None, figsize=None, filename=None, display=True)
<div align="right"><a href="https://github.com/tvdboom/ATOM/blob/master/atom/plots.py#L437">[source]</a></div></pre>
<p>This <code>@contextmanager</code> allows you to draw many plots in one figure. The default
option is to add two plots side by side. See the <a href="../../../user_guide/#canvas">user guide</a>
for an example use case.</p>
<table>
<tr>
<td width="15%" style="vertical-align:top; background:#F5F5F5;"><strong>Parameters:</strong></td>
<td width="75%" style="background:white;">
<strong>nrows: int, optional (default=1)</strong>
<blockquote>
Number of plots in length.
</blockquote>
<strong>ncols: int, optional (default=2)</strong>
<blockquote>
Number of plots in width.
</blockquote>
<strong>title: str or None, optional (default=None)</strong>
<blockquote>
Plot's title. If None, no title is displayed.
</blockquote>
<strong>figsize: tuple or None, optional (default=None)</strong>
<blockquote>
Figure's size, format as (x, y). If None, adapts size to the number of plots
 in the canvas.
</blockquote>
<strong>filename: str or None, optional (default=None)</strong>
<blockquote>
Name of the file. If None, the figure is not saved.
</blockquote>
<strong>display: bool, optional (default=True)</strong>
<blockquote>
Whether to render the plot.
</blockquote>
</tr>
</table>
<p><br /></p>
<p><a name="delete"></a></p>
<pre><em>method</em> <strong style="color:#008AB8">delete</strong>(models=None)
<div align="right"><a href="https://github.com/tvdboom/ATOM/blob/master/atom/basepredictor.py#L340">[source]</a></div></pre>
<p>Removes a model from the pipeline. If all models in the pipeline are removed,
the metric is reset. Use this method to remove unwanted models or to free
some memory before saving the instance.</p>
<table>
<tr>
<td width="15%" style="vertical-align:top; background:#F5F5F5;"><strong>Parameters:</strong></td>
<td width="75%" style="background:white;">
<strong>models: str or sequence, optional (default=None)</strong>
<blockquote>
Name of the models to clear from the pipeline. If None, clear all models.
</blockquote>
</tr>
</table>
<p><br /></p>
<p><a name="export-pipeline"></a></p>
<pre><em>method</em> <strong style="color:#008AB8">export_pipeline</strong>(model=None)
<div align="right"><a href="https://github.com/tvdboom/ATOM/blob/master/atom/atom.py#L347">[source]</a></div></pre>
<p>Export atom's pipeline to a sklearn's Pipeline. Optionally, you can add a model
as final estimator. If the model needs feature scaling and there is no scaler in
the pipeline, a <a href="https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html">StandardScaler</a>
will be added. The returned pipeline is already fitted.</p>
<table>
<tr>
<td width="15%" style="vertical-align:top; background:#F5F5F5;"><strong>Parameters:</strong></td>
<td width="75%" style="background:white;">
<strong>model: str or None, optional (default=None)</strong>
<blockquote>
Name of the model to add as a final estimator to the
pipeline. If None, no model is added.
</blockquote>
</tr>
<tr>
<td width="15%" style="vertical-align:top; background:#F5F5F5;"><strong>Returns:</strong></td>
<td width="75%" style="background:white;">
<strong>pipeline: <a href="https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html">Pipeline</a></strong>
<blockquote>
Pipeline in the current branch as a sklearn object.
</blockquote>
</tr>
</table>
<p><br /></p>
<p><a name="log"></a></p>
<pre><em>method</em> <strong style="color:#008AB8">log</strong>(msg, level=0)
<div align="right"><a href="https://github.com/tvdboom/ATOM/blob/master/atom/basetransformer.py#L309">[source]</a></div></pre>
<p>Write a message to the logger and print it to stdout.</p>
<table>
<tr>
<td width="15%" style="vertical-align:top; background:#F5F5F5;"><strong>Parameters:</strong></td>
<td width="75%" style="background:white;">
<strong>msg: str</strong>
<blockquote>
Message to write to the logger and print to stdout.
</blockquote>
<strong>level: int, optional (default=0)</strong>
<blockquote>
Minimum verbosity level to print the message.
</blockquote>
</tr>
</table>
<p><br /></p>
<p><a name="report"></a></p>
<pre><em>method</em> <strong style="color:#008AB8">report</strong>(dataset="dataset", n_rows=None, filename=None)
<div align="right"><a href="https://github.com/tvdboom/ATOM/blob/master/atom/atom.py#L219">[source]</a></div></pre>
<p>Create an extensive profile analysis report of the data. The report is rendered
in HTML5 and CSS3. Note that this method can be slow for <code>n_rows</code> &gt; 10k.</p>
<table>
<tr>
<td width="15%" style="vertical-align:top; background:#F5F5F5;"><strong>Parameters:</strong></td>
<td width="75%" style="background:white;">
<strong>dataset: str, optional (default="dataset")</strong>
<blockquote>
Data set to get the report from.
</blockquote>
<strong>n_rows: int or None, optional (default=None)</strong>
<blockquote>
Number of (randomly picked) rows to process. None for all rows.
</blockquote>
<strong>filename: str or None, optional (default=None)</strong>
<blockquote>
Name to save the file with (as .html). None to not save anything.
</blockquote>
</tr>
<tr>
<td width="15%" style="vertical-align:top; background:#F5F5F5;"><strong>Returns:</strong></td>
<td width="75%" style="background:white;">
<strong>report: <a href="https://pandas-profiling.github.io/pandas-profiling/docs/master/rtd/pages/api/_autosummary/pandas_profiling.profile_report.ProfileReport.html#pandas_profiling.profile_report.ProfileReport">ProfileReport</a></strong>
<blockquote>
Created profile object.
</blockquote>
</tr>
</table>
<p><br /></p>
<p><a name="reset-aesthetics"></a></p>
<pre><em>method</em> <strong style="color:#008AB8">reset_aesthetics</strong>()
<div align="right"><a href="https://github.com/tvdboom/ATOM/blob/master/atom/plots.py#L194">[source]</a></div></pre>
<p>Reset the <a href="../../../user_guide/#aesthetics">plot aesthetics</a> to their default values.
<br /><br /><br /></p>
<p><a name="reset-predictions"></a></p>
<pre><em>method</em> <strong style="color:#008AB8">reset_predictions</strong>()
<div align="right"><a href="https://github.com/tvdboom/ATOM/blob/master/atom/basepredictor.py#L98">[source]</a></div></pre>
<p>Clear the <a href="../../../user_guide/#predicting">prediction attributes</a> from all models.
 Use this method to free some memory before saving the trainer.
<br /><br /><br /></p>
<p><a name="save"></a></p>
<pre><em>method</em> <strong style="color:#008AB8">save</strong>(filename=None, save_data=True)
<div align="right"><a href="https://github.com/tvdboom/ATOM/blob/master/atom/basetransformer.py#L333">[source]</a></div></pre>
<p>Save the instance to a pickle file. Remember that the class contains the complete
dataset as attribute, so the file can become large for big datasets! To avoid this,
use <code>save_data=False</code>.</p>
<table>
<tr>
<td width="15%" style="vertical-align:top; background:#F5F5F5;"><strong>Parameters:</strong></td>
<td width="75%" style="background:white;">
<strong>filename: str or None, optional (default=None)</strong>
<blockquote>
Name to save the file with. None or "auto" to save with
 the __name__ of the class.
</blockquote>
<strong>save_data: bool, optional (default=True)</strong>
<blockquote>
Whether to save the data as an attribute of the instance. If False, remember to
 add the data to <a href="../../ATOM/atomloader">ATOMLoader</a> when loading the file.
</blockquote>
</tr>
</table>
<p><br></p>
<p><a name="save-data"></a></p>
<pre><em>method</em> <strong style="color:#008AB8">save_data</strong>(filename=None, dataset="dataset")
<div align="right"><a href="https://github.com/tvdboom/ATOM/blob/master/atom/atom.py#L308">[source]</a></div></pre>
<p>Save the data in the current branch to a csv file.</p>
<table>
<tr>
<td width="15%" style="vertical-align:top; background:#F5F5F5;"><strong>Parameters:</strong></td>
<td width="75%" style="background:white;">
<strong>filename: str or None, optional (default=None)</strong>
<blockquote>
Name to save the file with. None or "auto" for default name.
</blockquote>
<strong>dataset: str, optional (default="dataset")</strong>
<blockquote>
Data set to save.
</blockquote>
</tr>
</table>
<p><br></p>
<p><a name="scoring"></a></p>
<pre><em>method</em> <strong style="color:#008AB8">scoring</strong>(metric=None, dataset="test", **kwargs)
<div align="right"><a href="https://github.com/tvdboom/ATOM/blob/master/atom/basepredictor.py#L296">[source]</a></div></pre>
<p>Print all the models' scoring for a specific metric.</p>
<table>
<tr>
<td width="15%" style="vertical-align:top; background:#F5F5F5;"><strong>Parameters:</strong></td>
<td width="75%" style="background:white;">
<strong>metric: str or None, optional (default=None)</strong>
<blockquote>
Name of the metric to calculate. Choose from any of sklearn's regression <a href="https://scikit-learn.org/stable/modules/model_evaluation.html#the-scoring-parameter-defining-model-evaluation-rules">SCORERS</a>.
If None, returns the models' final results (ignores the <code>dataset</code> parameter).
</blockquote>
<strong>dataset: str, optional (default="test")</strong>
<blockquote>
Additional keyword arguments for the metric function.
</blockquote>
</table>
<p><br /></p>
<p><a name="stacking"></a></p>
<pre><em>method</em> <strong style="color:#008AB8">stacking</strong>(models=None, estimator=None, stack_method="auto", passthrough=False)
<div align="right"><a href="https://github.com/tvdboom/ATOM/blob/master/atom/basepredictor#L213">[source]</a></div></pre>
<p>Add a Stacking instance to the models in the pipeline.</p>
<table>
<tr>
<td width="15%" style="vertical-align:top; background:#F5F5F5;"><strong>Parameters:</strong></td>
<td width="75%" style="background:white;">
<strong>models: sequence or None, optional (default=None)</strong>
<blockquote>
Models that feed the stacking.
</blockquote>
<strong>estimator: str, callable or None, optional (default=None)</strong>
<blockquote>
The final estimator, which will be used to combine the base estimators. If str,
choose from ATOM's <a href="../../../user_guide/#predefined-models">predefined models</a>.
If None, <a href="https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Ridge.html">Ridge</a> is selected.
</blockquote>
<strong>stack_method: str, optional (default="auto")</strong>
<blockquote>
Methods called for each base estimator. If "auto", it will try to 
invoke <code>predict_proba</code>, <code>decision_function</code>
or <code>predict</code> in that order.
</blockquote>
<strong>passthrough: bool, optional (default=False)</strong>
<blockquote>
When False, only the predictions of estimators will be used
as training data for the final estimator. When True, the
estimator is trained on the predictions as well as the
original training data. The passed dataset will be scaled
if any of the models require scaled features and they are
not already.
</blockquote>
</tr>
</table>
<p><br /></p>
<p><a name="stats"></a></p>
<pre><em>method</em> <strong style="color:#008AB8">stats</strong>()
<div align="right"><a href="https://github.com/tvdboom/ATOM/blob/master/atom/atom.py#L178">[source]</a></div></pre>
<p>Print basic information about the dataset.
<br /><br /><br /></p>
<p><a name="voting"></a></p>
<pre><em>method</em> <strong style="color:#008AB8">voting</strong>(models=None, weights=None)
<div align="right"><a href="https://github.com/tvdboom/ATOM/blob/master/atom/basepredictor#L180">[source]</a></div></pre>
<p>Add a Voting instance to the models in the pipeline.</p>
<table>
<tr>
<td width="15%" style="vertical-align:top; background:#F5F5F5;"><strong>Parameters:</strong></td>
<td width="75%" style="background:white;">
<strong>models: sequence or None, optional (default=None)</strong>
<blockquote>
Models that feed the voting.
</blockquote>
<strong>weights: sequence or None, optional (default=None)</strong>
<blockquote>
Sequence of weights (int or float) to weight the
 occurrences of predicted class labels (hard voting)
 or class probabilities before averaging (soft voting).
 Uses uniform weights if None.
</blockquote>
</tr>
</table>
<p><br /><br /></p>
<h2 id="data-cleaning">Data cleaning</h2>
<hr />
<p>ATOMRegressor provides data cleaning methods to scale your features and handle
missing values, categorical columns and outliers. Calling on one of them will
automatically apply the method on the dataset in the pipeline.</p>
<div class="admonition tip">
<p class="admonition-title">Tip</p>
<p>Use the <a href="#report">report</a> method to examine the data and help you
determine suitable parameters for the data cleaning methods.</p>
</div>
<table>
<tr>
<td><a href="#scale">scale</a></td>
<td>Scale the dataset.</td>
</tr>

<tr>
<td><a href="#clean">clean</a></td>
<td>Applies standard data cleaning steps on the dataset.</td>
</tr>

<tr>
<td><a href="#impute">impute</a></td>
<td>Handle missing values in the dataset.</td>
</tr>

<tr>
<td><a href="#encode">encode</a></td>
<td>Encode categorical features.</td>
</tr>

<tr>
<td><a href="#prune">prune</a></td>
<td>Prune outliers from the training set.</td>
</tr>
</table>
<p><br></p>
<p><a name="scale"></a></p>
<pre><em>method</em> <strong style="color:#008AB8">scale</strong>(strategy="standard")
<div align="right"><a href="https://github.com/tvdboom/ATOM/blob/master/atom/atom.py#L340">[source]</a></div></pre>
<p>Applies one of sklearn's scalers. Non-numerical columns are ignored (instead
of raising an exception). See the <a href="../../data_cleaning/scaler/">Scaler</a> class.
<br /><br /><br /></p>
<p><a name="clean"></a></p>
<pre><em>method</em> <strong style="color:#008AB8">clean</strong>(prohibited_types=None, strip_categorical=True, maximum_cardinality=True,
             minimum_cardinality=True, missing_target=True, encode_target=None) 
<div align="right"><a href="https://github.com/tvdboom/ATOM/blob/master/atom/atom.py#L359">[source]</a></div></pre>
<p>Applies standard data cleaning steps on the dataset. Use the parameters
to choose which transformations to perform. The available steps are:</p>
<ul>
<li>Remove columns with prohibited data types.</li>
<li>Remove categorical columns with maximal cardinality.</li>
<li>Remove columns with minimum cardinality.</li>
<li>Strip categorical features from white spaces.</li>
<li>Drop duplicate rows.</li>
<li>Drop rows with missing values in the target column.</li>
<li>Encode the target column.</li>
</ul>
<p>See <a href="../../data_cleaning/cleaner/">Cleaner</a> for a description of the parameters.
<br /><br /><br /></p>
<p><a name="impute"></a></p>
<pre><em>method</em> <strong style="color:#008AB8">impute</strong>(strat_num="drop", strat_cat="drop", min_frac_rows=0.5, min_frac_cols=0.5, missing=None) 
<div align="right"><a href="https://github.com/tvdboom/ATOM/blob/master/atom/atom.py#L412">[source]</a></div></pre>
<p>Impute or remove missing values according to the selected strategy. Also removes
rows and columns with too many missing values. The imputer is fitted only on the
training set to avoid data leakage. Use the <code>missing</code> attribute to customize what
are considered "missing values". See <a href="../../data_cleaning/imputer/">Imputer</a> for a
description of the parameters. Note that since the Imputer can remove rows from both
the train and test set, the size of the sets may change after the tranformation.
<br /><br /><br /></p>
<p><a name="encode"></a></p>
<pre><em>method</em> <strong style="color:#008AB8">encode</strong>(strategy="LeaveOneOut", max_onehot=10, frac_to_other=None)
<div align="right"><a href="https://github.com/tvdboom/ATOM/blob/master/atom/atom.py#L454">[source]</a></div></pre>
<p>Perform encoding of categorical features. The encoding type depends on the
 number of unique values in the column:</p>
<ul>
<li>If n_unique=2, use Label-encoding.</li>
<li>If 2 < n_unique <= max_onehot, use OneHot-encoding.</li>
<li>If n_unique > max_onehot, use `strategy`-encoding.</li>
</ul>
<p>Also replaces classes with low occurrences with the value <code>other</code> in
order to prevent too high cardinality. Categorical features are defined as
all columns whose dtype.kind not in <code>ifu</code>. Will raise an error if it encounters
missing values or unknown classes when transforming. The encoder is fitted only
on the training set to avoid data leakage. See <a href="../../data_cleaning/encoder/">Encoder</a>
for a description of the parameters.
<br /><br /><br /></p>
<p><a name="prune"></a></p>
<pre><em>method</em> <strong style="color:#008AB8">prune</strong>(strategy="z-score", method="drop", max_sigma=3, include_target=False, **kwargs)
<div align="right"><a href="https://github.com/tvdboom/ATOM/blob/master/atom/atom.py#L493">[source]</a></div></pre>
<p>Prune outliers from the training set. The definition of outlier depends
on the selected strategy and can greatly differ from one each other. 
Ignores categorical columns. Only outliers from the training set are pruned
in order to maintain the original distribution of samples in the test
set. Ignores categorical columns. See <a href="../../data_cleaning/pruner/">Pruner</a>
for a description of the parameters.
<br /><br /><br /></p>
<h2 id="feature-engineering">Feature engineering</h2>
<hr />
<p>To further pre-process the data, you can create new non-linear features transforming
the existing ones or, if your dataset is too large, remove features using one
of the provided strategies.</p>
<table>
<tr>
<td><a href="#feature-generation">feature_generation</a></td>
<td>Create new features from combinations of existing ones.</td>
</tr>

<tr>
<td><a href="#feature-selection">feature_selection</a></td>
<td>Remove features according to the selected strategy.</td>
</tr>
</table>
<p><br></p>
<p><a name="feature-generation"></a></p>
<pre><em>method</em> <strong style="color:#008AB8">feature_generation</strong>(strategy="DFS", n_features=None, generations=20, population=500, operators=None)
<div align="right"><a href="https://github.com/tvdboom/ATOM/blob/master/atom/atom.py#L563">[source]</a></div></pre>
<p>Use Deep feature Synthesis or a genetic algorithm to create new combinations
of existing features to capture the non-linear relations between the original
features. See <a href="../../feature_engineering/feature_generator/">FeatureGenerator</a> for
a description of the parameters. Attributes created by the class are attached to
atom.
<br /><br /><br /></p>
<p><a name="feature-selection"></a></p>
<pre><em>method</em> <strong style="color:#008AB8">feature_selection</strong>(strategy=None, solver=None, n_features=None,
                         max_frac_repeated=1., max_correlation=1., **kwargs) 
<div align="right"><a href="https://github.com/tvdboom/ATOM/blob/master/atom/atom.py#L604">[source]</a></div></pre>
<p>Remove features according to the selected strategy. Ties between features with
equal scores will be broken in an unspecified way. Also removes features with
too low variance and finds pairs of collinear features based on the Pearson
correlation coefficient. For each pair above the specified limit (in terms of
absolute value), it removes one of the two. See <a href="../../feature_engineering/feature_selector/">FeatureSelector</a>
for a description of the parameters. Plotting methods and attributes created
by the class are attached to atom.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p><ul>
<li>When strategy="univariate" and solver=None, <a href="https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.f_classif.html">f_classif</a>
    will be used as default solver.</li>
<li>When strategy is one of SFM, RFE, RFECV or SFS and the solver is one of 
    ATOM's <a href="../../../user_guide/#predefined-models">predefined models</a>, the
    algorithm will automatically select the classifier (no need to add <code>_class</code>
    to the solver).</li>
<li>When strategy is one of SFM, RFE, RFECV or SFS and solver=None, ATOM will
     use the winning model (if it exists) as solver.</li>
<li>When strategy is RFECV or SFS, ATOM will use the metric in the pipeline
    (if it exists) as the scoring parameter (only if not specified).</li></p>
</div>
<p><br /><br /></p>
<h2 id="training">Training</h2>
<hr />
<p>The training methods are where the models are fitted to the data and their
performance is evaluated according to the selected metric. There are three
methods to call the three different training approaches in ATOM. All relevant
attributes and methods from the training classes are attached to atom for
convenience. These include the errors, winner and results attributes, as well
as the <a href="../../../user_guide/#models">models</a>, and the
<a href="../../../user_guide/#predicting">prediction</a> and
<a href="../../../user_guide/#plots">plotting</a> methods.</p>
<table>
<tr>
<td><a href="#run">run</a></td>
<td>Fit the models to the data in a direct fashion.</td>
</tr>

<tr>
<td><a href="#successive-halving">successive_halving</a></td>
<td>Fit the models to the data in a successive halving fashion.</td>
</tr>

<tr>
<td><a href="#train-sizing">train_sizing</a></td>
<td>Fit the models to the data in a train sizing fashion.</td>
</tr>
</table>
<p><br></p>
<p><a name="run"></a></p>
<pre><em>method</em> <strong style="color:#008AB8">run</strong>(models, metric=None, greater_is_better=True, needs_proba=False, needs_threshold=False,
           n_calls=10, n_initial_points=5, est_params=None, bo_params=None, bagging=0) 
<div align="right"><a href="https://github.com/tvdboom/ATOM/blob/master/atom/atom.py#L783">[source]</a></div></pre>
<p>Runs a <a href="../../training/directregressor/">DirectRegressor</a> instance.
<br /><br /><br /></p>
<p><a name="successive-halving"></a></p>
<pre><em>method</em> <strong style="color:#008AB8">successive_halving</strong>(models, metric=None, greater_is_better=True, needs_proba=False,
                          needs_threshold=False, skip_runs=0, n_calls=0, n_initial_points=5,
                          est_params=None, bo_params=None, bagging=0) 
<div align="right"><a href="https://github.com/tvdboom/ATOM/blob/master/atom/atom.py#L824">[source]</a></div></pre>
<p>Runs a <a href="../../training/successivehalvingregressor/">SuccessiveHalvingRegressor</a> instance.
<br /><br /><br /></p>
<p><a name="train-sizing"></a></p>
<pre><em>method</em> <strong style="color:#008AB8">train_sizing</strong>(models, metric=None, greater_is_better=True, needs_proba=False,
                    needs_threshold=False, train_sizes=np.linspace(0.2, 1.0, 5), n_calls=0,
                    n_initial_points=5, est_params=None, bo_params=None, bagging=0) 
<div align="right"><a href="https://github.com/tvdboom/ATOM/blob/master/atom/atom.py#L872">[source]</a></div></pre>
<p>Runs a <a href="../../training/trainsizingregressor/">TrainSizingRegressor</a> instance.
<br /><br /><br /></p>
<h2 id="example">Example</h2>
<hr />
<pre><code class="language-python">from sklearn.datasets import load_boston
from atom import ATOMRegressor

X, y = load_boston(return_X_y=True)

# Initialize class
atom = ATOMRegressor(X, y, logger=&quot;auto&quot;, n_jobs=2, verbose=2)

# Apply data cleaning methods
atom.prune(strategy=&quot;min_max&quot;, max_sigma=2, include_target=True)

# Fit the models to the data
atom.run(
    models=[&quot;OLS&quot;, &quot;BR&quot;, &quot;CatB&quot;],
    metric=&quot;MSE&quot;,
    n_calls=25,
    n_initial_points=10,
    bo_params={&quot;cv&quot;: 1},
    bagging=4
)

# Analyze the results
print(f&quot;The winning model is: {atom.winner.name}&quot;)
print(atom.results)

# Make some plots
atom.plot_errors(figsize=(9, 6), filename=&quot;errors.png&quot;)  
atom.CatB.plot_feature_importance(filename=&quot;catboost_feature_importance.png&quot;)

# Run an extra model
atom.run(
    models=&quot;MLP&quot;,
    metric=&quot;MSE&quot;,
    n_calls=25,
    n_initial_points=10,
    bo_params={&quot;cv&quot;: 1},
    bagging=4
)

# Get the predictions for the best model on new data
predictions = atom.predict(X_new)
</code></pre></div>
            </div>
        </div>

        <footer class="col-md-12">
            <hr>
                <p> Copyright 2020, by tvdboom.</p>
            <p>Documentation built with <a href="https://www.mkdocs.org/">MkDocs</a>.</p>
        </footer>
        <script>
            var base_url = "../../..",
                shortcuts = {"help": 191, "next": 78, "previous": 80, "search": 83};
        </script>
        <script src="../../../js/base.js" defer></script>
        <script src="../../../search/main.js" defer></script>

        <div class="modal" id="mkdocs_search_modal" tabindex="-1" role="dialog" aria-labelledby="searchModalLabel" aria-hidden="true">
    <div class="modal-dialog modal-lg">
        <div class="modal-content">
            <div class="modal-header">
                <h4 class="modal-title" id="searchModalLabel">Search</h4>
                <button type="button" class="close" data-dismiss="modal"><span aria-hidden="true">&times;</span><span class="sr-only">Close</span></button>
            </div>
            <div class="modal-body">
                <p>
                    From here you can search these documents. Enter
                    your search terms below.
                </p>
                <form>
                    <div class="form-group">
                        <input type="search" class="form-control" placeholder="Search..." id="mkdocs-search-query" title="Type search term here">
                    </div>
                </form>
                <div id="mkdocs-search-results"></div>
            </div>
            <div class="modal-footer">
            </div>
        </div>
    </div>
</div><div class="modal" id="mkdocs_keyboard_modal" tabindex="-1" role="dialog" aria-labelledby="keyboardModalLabel" aria-hidden="true">
    <div class="modal-dialog">
        <div class="modal-content">
            <div class="modal-header">
                <h4 class="modal-title" id="keyboardModalLabel">Keyboard Shortcuts</h4>
                <button type="button" class="close" data-dismiss="modal"><span aria-hidden="true">&times;</span><span class="sr-only">Close</span></button>
            </div>
            <div class="modal-body">
              <table class="table">
                <thead>
                  <tr>
                    <th style="width: 20%;">Keys</th>
                    <th>Action</th>
                  </tr>
                </thead>
                <tbody>
                  <tr>
                    <td class="help shortcut"><kbd>?</kbd></td>
                    <td>Open this help</td>
                  </tr>
                  <tr>
                    <td class="next shortcut"><kbd>n</kbd></td>
                    <td>Next page</td>
                  </tr>
                  <tr>
                    <td class="prev shortcut"><kbd>p</kbd></td>
                    <td>Previous page</td>
                  </tr>
                  <tr>
                    <td class="search shortcut"><kbd>s</kbd></td>
                    <td>Search</td>
                  </tr>
                </tbody>
              </table>
            </div>
            <div class="modal-footer">
            </div>
        </div>
    </div>
</div>

    </body>
</html>
